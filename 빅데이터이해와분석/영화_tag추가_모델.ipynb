{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6b9ba8",
   "metadata": {},
   "source": [
    "### ì˜í™” ë¦¬ë·°ì— ë”°ë¼ tagë¥¼ 10ê°œ ì •ë„ ì¶”ì¶œí•˜ëŠ” ëª¨ë¸ ì œì‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62734c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ê°€ì°½ë ¥ ì—°ì£¼ìì˜', 'ì—°ì¶œ ì§„ì§€í•´ìš”', 'ì—°ì¶œê³¼ ê°€ì°½ë ¥', 'ì—°ì£¼ì ë…íŠ¹í•˜êµ¬ìš”', 'ê¸°ë°˜ìœ¼ë¡œ ì—°ì¶œ', 'ì—¬ì ì—°ì¶œê³¼', 'í”¼ê°€ë¡œì—­ ì—°ì£¼ì', 'ì—°ì¶œ ë³¼ë§Œí•©ë‹ˆë‹¤', 'ë…íŠ¹í•˜êµ¬ìš” íƒ„íƒ„í•œ', 'ë³¼ë§Œí•©ë‹ˆë‹¤ í”¼ê°€ë¡œì—­', 'ì—°ì£¼ìì˜ ì†Œë¦¬', 'ì§„ì§€í•´ìš” ì—¬ì', 'ë¬´ëŒ€ ì—°ì¶œ', 'ì—°ì¶œê³¼', 'ì—°ì£¼ìì˜', 'ì§„ì§€í•´ìš”', 'ì—°ì¶œ', 'ë…íŠ¹í•˜êµ¬ìš”', 'ì—°ì£¼ì', 'ê°€ì°½ë ¥', 'ë„ˆë¬´ ì§„ì§€', 'ë³¼ë§Œí•©ë‹ˆë‹¤', 'ì§„ì§€ ë¬´ëŒ€', 'í”¼ê°€ë¡œì—­', 'ì†Œë¦¬ ê¸°ë°˜ìœ¼ë¡œ', 'ì—¬ì', 'ê¸°ë°˜ìœ¼ë¡œ', 'íƒ„íƒ„í•œ', 'ì§„ì§€', 'ì†Œë¦¬']\n"
     ]
    }
   ],
   "source": [
    "#keybert í…ŒìŠ¤íŠ¸\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "reviews = [\n",
    "    'ë„ˆë¬´ ì§„ì§€', \n",
    "    'ë¬´ëŒ€ ì—°ì¶œ', \n",
    "    'ì§„ì§€í•´ìš” ì—¬ì',\n",
    "    'ì—°ì¶œê³¼ ê°€ì°½ë ¥', \n",
    "    'ì—°ì£¼ìì˜ ì†Œë¦¬', \n",
    "    'ê¸°ë°˜ìœ¼ë¡œ ì—°ì¶œ', \n",
    "    'ë³¼ë§Œí•©ë‹ˆë‹¤', \n",
    "    'í”¼ê°€ë¡œì—­ ì—°ì£¼ì', \n",
    "    'ë…íŠ¹í•˜êµ¬ìš” íƒ„íƒ„í•œ'\n",
    "    ]\n",
    "\n",
    "\n",
    "full_text = \" \".join(reviews)\n",
    "keywords = kw_model.extract_keywords(full_text, top_n=30, keyphrase_ngram_range=(1, 2))\n",
    "\n",
    "print([kw[0] for kw in keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fe4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kw_model.extract_keywords(full_text, top_n=7, keyphrase_ngram_range=(1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e013895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì—°ì¶œê³¼', 'ì—°ì£¼ìì˜', 'ì§„ì§€í•´ìš”', 'ì—°ì¶œ', 'ë…íŠ¹í•˜êµ¬ìš”', 'ì—°ì£¼ì', 'ê°€ì°½ë ¥']\n"
     ]
    }
   ],
   "source": [
    "print([kw[0] for kw in keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a391dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ í‚¤ì›Œë“œ 2ë‹¨ê³„ ì¶”ì¶œ ì™„ë£Œ â†’ megabox_with_keywords.csv ì €ì¥ë¨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# ë¦¬ë·° ì—´ í•©ì¹˜ê¸°\n",
    "review_cols = [\"ë¦¬ë·°1\", \"ë¦¬ë·°2\", \"ë¦¬ë·°3\", \"ë¦¬ë·°4\", \"ë¦¬ë·°5\"]\n",
    "df[\"ì „ì²´ë¦¬ë·°\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# KeyBERT ì´ˆê¸°í™”\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# í‚¤ì›Œë“œ í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def clean_tags(tags):\n",
    "    tags = list(set(tags))                          # ì¤‘ë³µ ì œê±°\n",
    "    tags = [t for t in tags if len(t) > 1]          # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±°\n",
    "    tags = [re.sub(r\"[ì´ê°€ì„ë¥¼ì€ëŠ”ì—ì˜]$\", \"\", t) for t in tags]  # ì¡°ì‚¬ ì œê±°\n",
    "    return tags\n",
    "\n",
    "# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ (3ë‹¨ê³„ ì¶”ì¶œ)\n",
    "def extract_keywords_third(text):\n",
    "    try:\n",
    "        # 1ì°¨ ì¶”ì¶œ: ì›ë³¸ ë¦¬ë·°ì—ì„œ ìƒìœ„ 30ê°œ í‚¤ì›Œë“œ\n",
    "        first_keywords = kw_model.extract_keywords(text, top_n=30, keyphrase_ngram_range=(1, 2))\n",
    "        first_tags = [kw[0] for kw in first_keywords]\n",
    "        first_tags = clean_tags(first_tags)\n",
    "\n",
    "        # 2ì°¨ ì¶”ì¶œ: ì²« í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ ì…ë ¥\n",
    "        keyword_text = \" \".join(first_tags)\n",
    "        second_keywords = kw_model.extract_keywords(keyword_text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        second_tags = [kw[0] for kw in second_keywords]\n",
    "        second_tags = clean_tags(second_tags)\n",
    "        \n",
    "        # 3ì°¨ ì¶”ì¶œ: 2ì°¨ ì¶”ì¶œì˜ í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ ì…ë ¥\n",
    "        third_keywords = kw_model.extract_keywords(\" \".join(second_tags), top_n=5, keyphrase_ngram_range=(1, 2))\n",
    "        third_tags = [kw[0] for kw in third_keywords]\n",
    "        third_tags = clean_tags(third_tags)\n",
    "\n",
    "        return \", \".join(third_tags)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# í‚¤ì›Œë“œ ì¶”ì¶œ ì ìš©\n",
    "df[\"ë¦¬ë·°í‚¤ì›Œë“œ\"] = df[\"ì „ì²´ë¦¬ë·°\"].apply(extract_keywords_third)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv(\"megabox_with_keywords.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ‰ í‚¤ì›Œë“œ 2ë‹¨ê³„ ì¶”ì¶œ ì™„ë£Œ â†’ megabox_with_keywords.csv ì €ì¥ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da830cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ„ ë‹¨ê³„ê°€ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë¬¸ì œì  ìˆì–´. Okt ì“°ëŠ” ë°©í–¥ìœ¼ë¡œ ë³€ê²½\n",
    "from keybert import KeyBERT\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# ë¦¬ë·° ì—´ í•©ì¹˜ê¸°\n",
    "review_cols = [\"ë¦¬ë·°1\", \"ë¦¬ë·°2\", \"ë¦¬ë·°3\", \"ë¦¬ë·°4\", \"ë¦¬ë·°5\"]\n",
    "df[\"ì „ì²´ë¦¬ë·°\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "kw_model = KeyBERT()\n",
    "okt = Okt()\n",
    "\n",
    "# í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í‚¤ì›Œë“œ ì •ì œ í•¨ìˆ˜\n",
    "def extract_keywords_okt(text):\n",
    "    try:\n",
    "        keywords = kw_model.extract_keywords(text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        raw_phrases = [kw[0] for kw in keywords]\n",
    "\n",
    "        filtered_words = []\n",
    "        for phrase in raw_phrases:\n",
    "            tokens = okt.pos(phrase, stem=True)\n",
    "            for word, tag in tokens:\n",
    "                if tag in [\"Noun\", \"Adjective\", \"Verb\"] and len(word) > 1:\n",
    "                    filtered_words.append(word)\n",
    "\n",
    "        return \", \".join(sorted(set(filtered_words)))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# ì ìš©\n",
    "df[\"í˜•íƒœì†Œí‚¤ì›Œë“œ\"] = df[\"ì „ì²´ë¦¬ë·°\"].apply(extract_keywords_okt)\n",
    "df.to_csv(\"megabox_with_keywords_okt.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff34d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ ë„ì „...\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# ë¦¬ë·° ì—´ í•©ì¹˜ê¸°\n",
    "review_cols = [\"ë¦¬ë·°1\", \"ë¦¬ë·°2\", \"ë¦¬ë·°3\", \"ë¦¬ë·°4\", \"ë¦¬ë·°5\"]\n",
    "df[\"ì „ì²´ë¦¬ë·°\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# KeyBERT ì´ˆê¸°í™”\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# 1. KeyBERTë¡œ ë¦¬ë·°ë³„ ìƒìœ„ 30ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "df[\"ì´ˆê¸°í‚¤ì›Œë“œ\"] = df[\"ì „ì²´ë¦¬ë·°\"].apply(\n",
    "    lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=30, keyphrase_ngram_range=(1, 2))]\n",
    ")\n",
    "\n",
    "# 2. í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•© (TF-IDF ë²¡í„°í™”ìš©)\n",
    "df[\"ì´ˆê¸°í‚¤ì›Œë“œë¬¸ì¥\"] = df[\"ì´ˆê¸°í‚¤ì›Œë“œ\"].apply(lambda tags: \" \".join(tags))\n",
    "\n",
    "# 3. ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ TF-IDF í•™ìŠµ\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"ì´ˆê¸°í‚¤ì›Œë“œë¬¸ì¥\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 4. ê° ë¦¬ë·°ì—ì„œ TF-IDF ê¸°ì¤€ ìƒìœ„ Nê°œ í‚¤ì›Œë“œë§Œ ì„ íƒ\n",
    "def get_top_tfidf_keywords(row_idx, top_n=5):\n",
    "    row = tfidf_matrix[row_idx]\n",
    "    scores = row.toarray().flatten()\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    return \", \".join([feature_names[i] for i in top_indices])\n",
    "\n",
    "df[\"TFIDFí‚¤ì›Œë“œ\"] = [get_top_tfidf_keywords(i, top_n=5) for i in range(len(df))]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv(\"megabox_tfidf_filtered.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963d96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ìµœì¢… í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ â†’ megabox_final_keywords_tfidf.csv\n"
     ]
    }
   ],
   "source": [
    "# ë˜ ë‹¤ë¥¸ ë„ì „...\n",
    "\n",
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¦¬ë·° í•©ì¹˜ê¸°\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "review_cols = [\"ë¦¬ë·°1\", \"ë¦¬ë·°2\", \"ë¦¬ë·°3\", \"ë¦¬ë·°4\", \"ë¦¬ë·°5\"]\n",
    "df[\"ì „ì²´ë¦¬ë·°\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# 2. KeyBERT ë° Okt ì´ˆê¸°í™”\n",
    "kw_model = KeyBERT()\n",
    "okt = Okt()\n",
    "\n",
    "# 3. KeyBERT â†’ Okt â†’ ì •ì œëœ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "def extract_keywords_and_tokens(text):\n",
    "    try:\n",
    "        # KeyBERT ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ\n",
    "        keywords = kw_model.extract_keywords(text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        phrases = [kw[0] for kw in keywords]\n",
    "\n",
    "        # í˜•íƒœì†Œ ë¶„ì„: ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œ\n",
    "        refined_words = []\n",
    "        for phrase in phrases:\n",
    "            tokens = okt.pos(phrase, stem=True)\n",
    "            for word, tag in tokens:\n",
    "                if tag in [\"Noun\", \"Adjective\", \"Verb\"] and len(word) > 1:\n",
    "                    refined_words.append(word)\n",
    "\n",
    "        return \" \".join(refined_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 4. ë¦¬ë·°ë³„ ì •ì œëœ ë‹¨ì–´ ë¬¸ì¥ ìƒì„±\n",
    "df[\"ì •ì œë‹¨ì–´ë¬¸ì¥\"] = df[\"ì „ì²´ë¦¬ë·°\"].apply(extract_keywords_and_tokens)\n",
    "\n",
    "# 5. TF-IDF í•™ìŠµ\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"ì •ì œë‹¨ì–´ë¬¸ì¥\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 6. TF-IDF ê¸°ì¤€ ìƒìœ„ ë‹¨ì–´ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def get_top_tfidf(row_idx, top_n=5):\n",
    "    row = tfidf_matrix[row_idx]\n",
    "    scores = row.toarray().flatten()\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    return \", \".join([feature_names[i] for i in top_indices])\n",
    "\n",
    "# 7. ìµœì¢… í‚¤ì›Œë“œ ìƒì„±\n",
    "df[\"ìµœì¢…í‚¤ì›Œë“œ\"] = [get_top_tfidf(i) for i in range(len(df))]\n",
    "\n",
    "# 8. ì €ì¥\n",
    "df.to_csv(\"megabox_final_keywords_tfidf.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ‰ ìµœì¢… í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ â†’ megabox_final_keywords_tfidf.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
