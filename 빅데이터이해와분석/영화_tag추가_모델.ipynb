{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6b9ba8",
   "metadata": {},
   "source": [
    "### 영화 리뷰에 따라 tag를 10개 정도 추출하는 모델 제작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62734c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가창력 연주자의', '연출 진지해요', '연출과 가창력', '연주자 독특하구요', '기반으로 연출', '여자 연출과', '피가로역 연주자', '연출 볼만합니다', '독특하구요 탄탄한', '볼만합니다 피가로역', '연주자의 소리', '진지해요 여자', '무대 연출', '연출과', '연주자의', '진지해요', '연출', '독특하구요', '연주자', '가창력', '너무 진지', '볼만합니다', '진지 무대', '피가로역', '소리 기반으로', '여자', '기반으로', '탄탄한', '진지', '소리']\n"
     ]
    }
   ],
   "source": [
    "#keybert 테스트\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "reviews = [\n",
    "    '너무 진지', \n",
    "    '무대 연출', \n",
    "    '진지해요 여자',\n",
    "    '연출과 가창력', \n",
    "    '연주자의 소리', \n",
    "    '기반으로 연출', \n",
    "    '볼만합니다', \n",
    "    '피가로역 연주자', \n",
    "    '독특하구요 탄탄한'\n",
    "    ]\n",
    "\n",
    "\n",
    "full_text = \" \".join(reviews)\n",
    "keywords = kw_model.extract_keywords(full_text, top_n=30, keyphrase_ngram_range=(1, 2))\n",
    "\n",
    "print([kw[0] for kw in keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fe4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kw_model.extract_keywords(full_text, top_n=7, keyphrase_ngram_range=(1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e013895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['연출과', '연주자의', '진지해요', '연출', '독특하구요', '연주자', '가창력']\n"
     ]
    }
   ],
   "source": [
    "print([kw[0] for kw in keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a391dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 키워드 2단계 추출 완료 → megabox_with_keywords.csv 저장됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "import re\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# 리뷰 열 합치기\n",
    "review_cols = [\"리뷰1\", \"리뷰2\", \"리뷰3\", \"리뷰4\", \"리뷰5\"]\n",
    "df[\"전체리뷰\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# KeyBERT 초기화\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# 키워드 후처리 함수\n",
    "def clean_tags(tags):\n",
    "    tags = list(set(tags))                          # 중복 제거\n",
    "    tags = [t for t in tags if len(t) > 1]          # 너무 짧은 단어 제거\n",
    "    tags = [re.sub(r\"[이가을를은는에의]$\", \"\", t) for t in tags]  # 조사 제거\n",
    "    return tags\n",
    "\n",
    "# 키워드 추출 함수 (3단계 추출)\n",
    "def extract_keywords_third(text):\n",
    "    try:\n",
    "        # 1차 추출: 원본 리뷰에서 상위 30개 키워드\n",
    "        first_keywords = kw_model.extract_keywords(text, top_n=30, keyphrase_ngram_range=(1, 2))\n",
    "        first_tags = [kw[0] for kw in first_keywords]\n",
    "        first_tags = clean_tags(first_tags)\n",
    "\n",
    "        # 2차 추출: 첫 키워드 리스트를 다시 하나의 문장으로 만들어 입력\n",
    "        keyword_text = \" \".join(first_tags)\n",
    "        second_keywords = kw_model.extract_keywords(keyword_text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        second_tags = [kw[0] for kw in second_keywords]\n",
    "        second_tags = clean_tags(second_tags)\n",
    "        \n",
    "        # 3차 추출: 2차 추출의 키워드를 다시 하나의 문장으로 만들어 입력\n",
    "        third_keywords = kw_model.extract_keywords(\" \".join(second_tags), top_n=5, keyphrase_ngram_range=(1, 2))\n",
    "        third_tags = [kw[0] for kw in third_keywords]\n",
    "        third_tags = clean_tags(third_tags)\n",
    "\n",
    "        return \", \".join(third_tags)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 키워드 추출 적용\n",
    "df[\"리뷰키워드\"] = df[\"전체리뷰\"].apply(extract_keywords_third)\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(\"megabox_with_keywords.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"🎉 키워드 2단계 추출 완료 → megabox_with_keywords.csv 저장됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da830cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 단계가 너무 오래 걸리는 문제점 있어. Okt 쓰는 방향으로 변경\n",
    "from keybert import KeyBERT\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# 리뷰 열 합치기\n",
    "review_cols = [\"리뷰1\", \"리뷰2\", \"리뷰3\", \"리뷰4\", \"리뷰5\"]\n",
    "df[\"전체리뷰\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# 모델 초기화\n",
    "kw_model = KeyBERT()\n",
    "okt = Okt()\n",
    "\n",
    "# 형태소 분석 기반 키워드 정제 함수\n",
    "def extract_keywords_okt(text):\n",
    "    try:\n",
    "        keywords = kw_model.extract_keywords(text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        raw_phrases = [kw[0] for kw in keywords]\n",
    "\n",
    "        filtered_words = []\n",
    "        for phrase in raw_phrases:\n",
    "            tokens = okt.pos(phrase, stem=True)\n",
    "            for word, tag in tokens:\n",
    "                if tag in [\"Noun\", \"Adjective\", \"Verb\"] and len(word) > 1:\n",
    "                    filtered_words.append(word)\n",
    "\n",
    "        return \", \".join(sorted(set(filtered_words)))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 적용\n",
    "df[\"형태소키워드\"] = df[\"전체리뷰\"].apply(extract_keywords_okt)\n",
    "df.to_csv(\"megabox_with_keywords_okt.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff34d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 도전...\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "\n",
    "# 리뷰 열 합치기\n",
    "review_cols = [\"리뷰1\", \"리뷰2\", \"리뷰3\", \"리뷰4\", \"리뷰5\"]\n",
    "df[\"전체리뷰\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# KeyBERT 초기화\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# 1. KeyBERT로 리뷰별 상위 30개 키워드 추출\n",
    "df[\"초기키워드\"] = df[\"전체리뷰\"].apply(\n",
    "    lambda x: [kw[0] for kw in kw_model.extract_keywords(x, top_n=30, keyphrase_ngram_range=(1, 2))]\n",
    ")\n",
    "\n",
    "# 2. 키워드 리스트를 하나의 문자열로 결합 (TF-IDF 벡터화용)\n",
    "df[\"초기키워드문장\"] = df[\"초기키워드\"].apply(lambda tags: \" \".join(tags))\n",
    "\n",
    "# 3. 전체 문서에 대해 TF-IDF 학습\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"초기키워드문장\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 4. 각 리뷰에서 TF-IDF 기준 상위 N개 키워드만 선택\n",
    "def get_top_tfidf_keywords(row_idx, top_n=5):\n",
    "    row = tfidf_matrix[row_idx]\n",
    "    scores = row.toarray().flatten()\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    return \", \".join([feature_names[i] for i in top_indices])\n",
    "\n",
    "df[\"TFIDF키워드\"] = [get_top_tfidf_keywords(i, top_n=5) for i in range(len(df))]\n",
    "\n",
    "# 결과 저장\n",
    "df.to_csv(\"megabox_tfidf_filtered.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963d96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 최종 키워드 추출 및 저장 완료 → megabox_final_keywords_tfidf.csv\n"
     ]
    }
   ],
   "source": [
    "# 또 다른 도전...\n",
    "\n",
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. 데이터 불러오기 및 리뷰 합치기\n",
    "df = pd.read_csv(\"1.megabox_reviews_merged_avg.csv\")\n",
    "review_cols = [\"리뷰1\", \"리뷰2\", \"리뷰3\", \"리뷰4\", \"리뷰5\"]\n",
    "df[\"전체리뷰\"] = df[review_cols].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "# 2. KeyBERT 및 Okt 초기화\n",
    "kw_model = KeyBERT()\n",
    "okt = Okt()\n",
    "\n",
    "# 3. KeyBERT → Okt → 정제된 단어 리스트 추출\n",
    "def extract_keywords_and_tokens(text):\n",
    "    try:\n",
    "        # KeyBERT 상위 10개 키워드\n",
    "        keywords = kw_model.extract_keywords(text, top_n=10, keyphrase_ngram_range=(1, 2))\n",
    "        phrases = [kw[0] for kw in keywords]\n",
    "\n",
    "        # 형태소 분석: 명사, 형용사, 동사만 추출\n",
    "        refined_words = []\n",
    "        for phrase in phrases:\n",
    "            tokens = okt.pos(phrase, stem=True)\n",
    "            for word, tag in tokens:\n",
    "                if tag in [\"Noun\", \"Adjective\", \"Verb\"] and len(word) > 1:\n",
    "                    refined_words.append(word)\n",
    "\n",
    "        return \" \".join(refined_words)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 4. 리뷰별 정제된 단어 문장 생성\n",
    "df[\"정제단어문장\"] = df[\"전체리뷰\"].apply(extract_keywords_and_tokens)\n",
    "\n",
    "# 5. TF-IDF 학습\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"정제단어문장\"])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 6. TF-IDF 기준 상위 단어 추출 함수\n",
    "def get_top_tfidf(row_idx, top_n=5):\n",
    "    row = tfidf_matrix[row_idx]\n",
    "    scores = row.toarray().flatten()\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    return \", \".join([feature_names[i] for i in top_indices])\n",
    "\n",
    "# 7. 최종 키워드 생성\n",
    "df[\"최종키워드\"] = [get_top_tfidf(i) for i in range(len(df))]\n",
    "\n",
    "# 8. 저장\n",
    "df.to_csv(\"megabox_final_keywords_tfidf.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"🎉 최종 키워드 추출 및 저장 완료 → megabox_final_keywords_tfidf.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
